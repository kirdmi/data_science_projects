# Online Store Project: Toxic Comment Moderation

As part of the online store project, a service is being launched that enables customers to supplement and edit product descriptions. To ensure the integrity of the content, a tool needs to be developed that can effectively detect toxic comments and send them for moderation.

The goal is to create a tool that achieves a minimum quality metric of F1 score of 0.75, indicating reliable detection of toxic comments. To accomplish this, various libraries such as pandas, numpy, nltk, sklearn, lightgbm, pymystem3, spacy, and re will be utilized. The tool will be designed to effectively search for toxic comments, enabling timely and accurate moderation to maintain a safe and respectful online environment for customers.